{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6a3e386b-42eb-4c8d-bce2-9cfc476a347e",
      "metadata": {
        "id": "6a3e386b-42eb-4c8d-bce2-9cfc476a347e"
      },
      "source": [
        "Importing Relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9002377-0bf6-4be0-8df2-f8f886ad1b60",
      "metadata": {
        "id": "c9002377-0bf6-4be0-8df2-f8f886ad1b60"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import pydicom\n",
        "import pandas as pd\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Resize, Compose\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d2f2ac3-7695-4cae-bb91-43f47038ad73",
      "metadata": {
        "id": "6d2f2ac3-7695-4cae-bb91-43f47038ad73"
      },
      "source": [
        "Helper functions for Loading Series\n",
        "TODO: EXPAND TO FULL SET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5af1a042-2297-4ae9-8fef-7d21c3472a09",
      "metadata": {
        "id": "5af1a042-2297-4ae9-8fef-7d21c3472a09"
      },
      "outputs": [],
      "source": [
        "# Function to load DICOM series\n",
        "def load_dicom_series(series_dir, target_size=(224, 224)):\n",
        "    \"\"\"Load and normalize a DICOM series, return (1, H, W)\"\"\"\n",
        "    \"\"\"    #This is within the single folder-- this is within a single series (ex. 01-01-1990-NA-MRI BREAST BILATERAL WWO-97538\\26.000000-ax t1 tse c-58582)\n",
        "\"\"\"\n",
        "    slices = []\n",
        "    for file in sorted(os.listdir(series_dir)):\n",
        "        if file.endswith('.dcm'):\n",
        "            dcm = pydicom.dcmread(os.path.join(series_dir, file))\n",
        "            slices.append(dcm.pixel_array.astype(np.float32))\n",
        "    volume = np.stack(slices, axis=0)\n",
        "\n",
        "    # Collapse Z\n",
        "    image = np.mean(volume, axis=0)\n",
        "    image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-5)\n",
        "\n",
        "    image = torch.tensor(image).unsqueeze(0)  # (1, H, W)\n",
        "    image = torch.nn.functional.interpolate(image.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False)\n",
        "    return image.squeeze(0)  # (1, H, W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "577e1004-3ca1-465d-863d-dc70d7e1198a",
      "metadata": {
        "id": "577e1004-3ca1-465d-863d-dc70d7e1198a"
      },
      "outputs": [],
      "source": [
        "# Function to load DICOM series seg\n",
        "def load_nrrd_mask(nrrd_path):\n",
        "    #all nrrd should be available, something has gone wrong if not\n",
        "    \"\"\"Load NRRD segmentation mask and return binary mask tensor (1, H, W)\"\"\"\n",
        "    if not os.path.exists(nrrd_path):\n",
        "        return None\n",
        "    image = sitk.ReadImage(nrrd_path)\n",
        "    array = sitk.GetArrayFromImage(image)  # shape: (Z, H, W)\n",
        "    mask = (array > 0).astype(np.float32)\n",
        "    if mask.shape[0] > 1:\n",
        "        mask = np.mean(mask, axis=0)\n",
        "    else:\n",
        "        mask = mask[0]\n",
        "    return torch.tensor(mask).unsqueeze(0)  # shape: (1, H, W)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4441806-653c-4cfe-8ce6-e8f6b026fb8c",
      "metadata": {
        "id": "e4441806-653c-4cfe-8ce6-e8f6b026fb8c"
      },
      "source": [
        "Test Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f90fe859-ca41-4546-be74-a34e3200c6a3",
      "metadata": {
        "id": "f90fe859-ca41-4546-be74-a34e3200c6a3"
      },
      "outputs": [],
      "source": [
        "class BreastMRIDataset(Dataset):\n",
        "    def __init__(self, series_dirs, mask_paths, labels, transform=None, use_mask=True):\n",
        "        \"\"\"\n",
        "        series_dirs: list of directories with DICOM series\n",
        "        mask_paths: list of NRRD mask file paths (can be None)\n",
        "        labels: list of outcome labels\n",
        "        \"\"\"\n",
        "        self.series_dirs = series_dirs\n",
        "        self.mask_paths = mask_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.use_mask = use_mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.series_dirs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = load_dicom_series(self.series_dirs[idx])  # (1, H, W)\n",
        "        mask = None\n",
        "        if self.use_mask and self.mask_paths[idx] is not None:\n",
        "            mask = load_nrrd_mask(self.mask_paths[idx])  # (1, H, W)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            if mask is not None:\n",
        "                mask = self.transform(mask)\n",
        "\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return image, mask, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d5534f-abeb-404f-8fba-650481eb4457",
      "metadata": {
        "id": "59d5534f-abeb-404f-8fba-650481eb4457"
      },
      "source": [
        "Functions for Accessing Training and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d822324-f87c-414f-99c0-871f13781fed",
      "metadata": {
        "id": "1d822324-f87c-414f-99c0-871f13781fed"
      },
      "outputs": [],
      "source": [
        "#pipeline:\n",
        "#trawl csv file of training ids\n",
        "#for every one, construct path to where the series is\n",
        "#for every one, construct path to where the mask (DENSE AND VESSELS) is\n",
        "#for every one return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "270290b4-443b-42f1-a02c-a8217ed778c3",
      "metadata": {
        "id": "270290b4-443b-42f1-a02c-a8217ed778c3"
      },
      "outputs": [],
      "source": [
        "def trawlIdFile():\n",
        "    dir_list = os.listdir(baselineLocationSeg)\n",
        "    print(dir_list)\n",
        "    df = pd.DataFrame(dir_list, columns=['Name'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5d43681-3dd0-47e7-94ce-49ef8e9faff9",
      "metadata": {
        "id": "f5d43681-3dd0-47e7-94ce-49ef8e9faff9"
      },
      "outputs": [],
      "source": [
        "def buildPathToSeries(patient):\n",
        "    currentDir = os.path.join(baselineLocationImgs, patient)\n",
        "    folders = [f for f in os.listdir(currentDir) if os.path.isdir(os.path.join(currentDir, f))]\n",
        "        # Check if there is at least one folder\n",
        "    if folders:\n",
        "        # Grab the first folder (im just expecting the one but just in case)\n",
        "        firstFolder = folders[0]\n",
        "        currentDir = os.path.join(currentDir, firstFolder)\n",
        "        currentDir = os.path.join(currentDir, \"T1_IMGS\")\n",
        "    return currentDir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c957156d-18a3-46fe-ad25-5da4c03be9e4",
      "metadata": {
        "id": "c957156d-18a3-46fe-ad25-5da4c03be9e4"
      },
      "outputs": [],
      "source": [
        "def buildPathToNrrd(patient):\n",
        "    currentDir = os.path.join(baselineLocationSeg, patient)\n",
        "    #Segmentation_Breast_MRI_018_Breast.seg.nrrd\n",
        "    string = \"Segmentation_\" + patient + \"_Breast.seg.nrrd\"\n",
        "    currentDir = os.path.join(currentDir, string)\n",
        "    return currentDir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a375d1a-9575-427a-8c44-a8cddde5ac2c",
      "metadata": {
        "id": "2a375d1a-9575-427a-8c44-a8cddde5ac2c"
      },
      "outputs": [],
      "source": [
        "def trawlMyRecurrences():\n",
        "    df = pd.read_csv(locationOfClin)\n",
        "    df['Recurrence'] = pd.to_numeric(df['Recurrence'], downcast='integer', errors='coerce')\n",
        "    print(df)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ad5ee0-d8da-4466-8fb5-5d7082c5c4f2",
      "metadata": {
        "id": "42ad5ee0-d8da-4466-8fb5-5d7082c5c4f2"
      },
      "outputs": [],
      "source": [
        "def constructSeriesDirAndMaskPaths():\n",
        "    series_dirs=[]\n",
        "    mask_paths=[]\n",
        "    df = trawlIdFile()\n",
        "    recurrencedf = trawlMyRecurrences()\n",
        "    filtered_rec = recurrencedf[recurrencedf['Name'].isin(df['Name'])]\n",
        "    labels = filtered_rec['Recurrence'].values.tolist()\n",
        "    print(labels)\n",
        "    for index, row in df.iterrows():\n",
        "        patient = row['Name']\n",
        "        #construct path to series\n",
        "        mgyPath = buildPathToSeries(patient)\n",
        "        if (os.path.exists(mgyPath)):\n",
        "            series_dirs.append(mgyPath)\n",
        "            mask_paths.append(buildPathToNrrd(patient))\n",
        "    return series_dirs, mask_paths, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c23f4a05-1884-4e63-96fc-697715f8b278",
      "metadata": {
        "id": "c23f4a05-1884-4e63-96fc-697715f8b278"
      },
      "outputs": [],
      "source": [
        "#put in pickl file  post-architecture so this isnt a pain for anyone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c813f61-3a38-4b85-8c24-1c95a2a1bd87",
      "metadata": {
        "id": "6c813f61-3a38-4b85-8c24-1c95a2a1bd87"
      },
      "outputs": [],
      "source": [
        "class TumorFeatureCNN(nn.Module):\n",
        "    def __init__(self, use_mask=False, in_channels=1):\n",
        "        super().__init__()\n",
        "        self.use_mask = use_mask\n",
        "        total_in = in_channels + (1 if use_mask else 0)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(total_in, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # squeeze to vector\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        if self.use_mask and mask is not None:\n",
        "            x = torch.cat([x, mask], dim=1)  # conca-ztenate channel-wise\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)  # flatten to (B, features)\n",
        "        return x  # features to send to RNN or FC layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dbca935-9bfd-4a5a-bb89-97c65a511c5b",
      "metadata": {
        "id": "5dbca935-9bfd-4a5a-bb89-97c65a511c5b"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  #Sanity check for dicom paths being real\n",
        "  test_dicom_path = r\"D:\\brc\\image\\manifest-1654812109500\\Duke-Breast-Cancer-MRI\\Breast_MRI_001\\01-01-1990-NA-MRI BREAST BILATERAL WWO-97538\\26.000000-ax t1 tse c-58582\"\n",
        "  print(os.path.exists(test_dicom_path))\n",
        "  testSeriesLoadStack = load_dicom_series(test_dicom_path)\n",
        "  print(testSeriesLoadStack)\n",
        "\n",
        "  #Sanity check for seg data\n",
        "  test_dicom_seg_path = r\"D:\\brc\\seg\\3dtest\\PKG - Duke-Breast-Cancer-MRI-Supplement-v3\\Duke-Breast-Cancer-MRI-Supplement-v3\\Segmentation_Masks_NRRD\\Breast_MRI_002\\Segmentation_Breast_MRI_002_Breast.seg.nrrd\"\n",
        "  print(os.path.exists(test_dicom_seg_path))\n",
        "  testDicomLoadSeries = load_nrrd_mask(test_dicom_seg_path)\n",
        "  print(testDicomLoadSeries)\n",
        "\n",
        "  baselineLocation = \"D:\\\\brc\\\\ids\"\n",
        "  baselineLocationImgs = \"D:\\\\brc\\\\image\\\\manifest-1654812109500\\\\Duke-Breast-Cancer-MRI\"\n",
        "  baselineLocationSeg = \"D:\\\\brc\\\\seg\\\\3dtest\\\\PKG - Duke-Breast-Cancer-MRI-Supplement-v3\\\\Duke-Breast-Cancer-MRI-Supplement-v3\\\\Segmentation_Masks_NRRD\"\n",
        "  locationOfClin = \"D:\\\\brc\\\\clin\\\\clinical.csv\"\n",
        "  print(os.path.exists(locationOfClin))\n",
        "\n",
        "  trawlMyRecurrences()\n",
        "\n",
        "  constructSeriesDirAndMaskPaths()\n",
        "\n",
        "  transform = Compose([\n",
        "      Resize((224, 224)),  # need to see if architecture allows for this\n",
        "  ])\n",
        "  series, masks, recLabels = constructSeriesDirAndMaskPaths()\n",
        "  dataset = BreastMRIDataset(\n",
        "      series_dirs=series,\n",
        "      mask_paths=masks,\n",
        "      labels=recLabels,\n",
        "      transform=transform,\n",
        "      use_mask=True,\n",
        "  )\n",
        "\n",
        "  loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "  # Create model instance\n",
        "  model = TumorFeatureCNN(use_mask=False, in_channels=1)  # adjust if needed\n",
        "\n",
        "  # Move to GPU if available\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = model.to(device)\n",
        "\n",
        "  df = trawlIdFile()\n",
        "  recurrencedf = trawlMyRecurrences()\n",
        "  filtered_rec = recurrencedf[recurrencedf['Name'].isin(df['Name'])]\n",
        "  patient_ids = filtered_rec['Name'].values.tolist()\n",
        "  print(patient_ids)\n",
        "\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "\n",
        "  all_features = []\n",
        "  all_labels = []\n",
        "  print(\"BEGIN TORCH\")\n",
        "  with torch.no_grad():\n",
        "      for inputs, masks, labels in loader:\n",
        "          masks = masks.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = model(inputs, masks)  # Get feature vector\n",
        "          all_features.append(outputs.cpu())\n",
        "          all_labels.append(labels.cpu())\n",
        "\n",
        "  # Stack all tensors\n",
        "  features_tensor = torch.cat(all_features)\n",
        "  labels_tensor = torch.cat(all_labels)\n",
        "  print(\"pickle time\")\n",
        "  # Save with pickle\n",
        "  with open(\"cnn_features.pkl\", \"wb\") as f:\n",
        "      pickle.dump({\n",
        "        'features': features_tensor.numpy(),\n",
        "        'labels':   labels_tensor.numpy(),\n",
        "        'ids':      patient_ids,\n",
        "      }, f)\n",
        "\n",
        "  print(\"Saved all CNN features and labels to cnn_features.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}