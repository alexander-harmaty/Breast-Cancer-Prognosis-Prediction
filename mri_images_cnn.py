# -*- coding: utf-8 -*-
"""MRI_Images_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l1y0rPdoFqOYpu2pZqgWNDbZDtoHTw4x

Importing Relevant Libraries
"""

import sys
import os

import pydicom
import pandas as pd
import SimpleITK as sitk
import numpy as np
import torch
from torch.utils.data import Dataset
from torchvision import transforms

"""Helper functions for Loading Series
TODO: EXPAND TO FULL SET
"""

# Function to load DICOM series
def load_dicom_series(series_dir, target_size=(224, 224)):
    """Load and normalize a DICOM series, return (1, H, W)"""
    """    #This is within the single folder-- this is within a single series (ex. 01-01-1990-NA-MRI BREAST BILATERAL WWO-97538\26.000000-ax t1 tse c-58582)
"""
    slices = []
    for file in sorted(os.listdir(series_dir)):
        if file.endswith('.dcm'):
            dcm = pydicom.dcmread(os.path.join(series_dir, file))
            slices.append(dcm.pixel_array.astype(np.float32))
    volume = np.stack(slices, axis=0)

    # Collapse Z
    image = np.mean(volume, axis=0)
    image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-5)

    image = torch.tensor(image).unsqueeze(0)  # (1, H, W)
    image = torch.nn.functional.interpolate(image.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False)
    return image.squeeze(0)  # (1, H, W)

# Function to load DICOM series seg
def load_nrrd_mask(nrrd_path):
    #all nrrd should be available, something has gone wrong if not
    """Load NRRD segmentation mask and return binary mask tensor (1, H, W)"""
    if not os.path.exists(nrrd_path):
        return None
    image = sitk.ReadImage(nrrd_path)
    array = sitk.GetArrayFromImage(image)  # shape: (Z, H, W)
    mask = (array > 0).astype(np.float32)
    if mask.shape[0] > 1:
        mask = np.mean(mask, axis=0)
    else:
        mask = mask[0]
    return torch.tensor(mask).unsqueeze(0)  # shape: (1, H, W)

#Sanity check for dicom paths being real
test_dicom_path = r"D:\brc\image\manifest-1654812109500\Duke-Breast-Cancer-MRI\Breast_MRI_001\01-01-1990-NA-MRI BREAST BILATERAL WWO-97538\26.000000-ax t1 tse c-58582"
print(os.path.exists(test_dicom_path))
testSeriesLoadStack = load_dicom_series(test_dicom_path)
print(testSeriesLoadStack)

#Sanity check for seg data
test_dicom_seg_path = r"D:\brc\seg\3dtest\PKG - Duke-Breast-Cancer-MRI-Supplement-v3\Duke-Breast-Cancer-MRI-Supplement-v3\Segmentation_Masks_NRRD\Breast_MRI_002\Segmentation_Breast_MRI_002_Breast.seg.nrrd"
print(os.path.exists(test_dicom_seg_path))
testDicomLoadSeries = load_nrrd_mask(test_dicom_seg_path)
print(testDicomLoadSeries)

"""Test Dataset Class"""

class BreastMRIDataset(Dataset):
    def __init__(self, series_dirs, mask_paths, labels, transform=None, use_mask=True):
        """
        series_dirs: list of directories with DICOM series
        mask_paths: list of NRRD mask file paths (can be None)
        labels: list of outcome labels
        """
        self.series_dirs = series_dirs
        self.mask_paths = mask_paths
        self.labels = labels
        self.transform = transform
        self.use_mask = use_mask

    def __len__(self):
        return len(self.series_dirs)

    def __getitem__(self, idx):
        image = load_dicom_series(self.series_dirs[idx])  # (1, H, W)
        mask = None
        if self.use_mask and self.mask_paths[idx] is not None:
            mask = load_nrrd_mask(self.mask_paths[idx])  # (1, H, W)

        if self.transform:
            image = self.transform(image)
            if mask is not None:
                mask = self.transform(mask)

        label = torch.tensor(self.labels[idx], dtype=torch.float32)
        return image, mask, label

"""Functions for Accessing Training and Test"""

#pipeline:
#trawl csv file of training ids
#for every one, construct path to where the series is
#for every one, construct path to where the mask (DENSE AND VESSELS) is
#for every one return label

baselineLocation = "D:\\brc\\ids"
baselineLocationImgs = "D:\\brc\\image\\manifest-1654812109500\\Duke-Breast-Cancer-MRI"
baselineLocationSeg = "D:\\brc\\seg\\3dtest\\PKG - Duke-Breast-Cancer-MRI-Supplement-v3\\Duke-Breast-Cancer-MRI-Supplement-v3\\Segmentation_Masks_NRRD"
locationOfClin = "D:\\brc\\clin\\clinical.csv"
print(os.path.exists(locationOfClin))

def trawlIdFile():
    dir_list = os.listdir(baselineLocationSeg)
    print(dir_list)
    df = pd.DataFrame(dir_list, columns=['Name'])
    return df

def buildPathToSeries(patient):
    currentDir = os.path.join(baselineLocationImgs, patient)
    folders = [f for f in os.listdir(currentDir) if os.path.isdir(os.path.join(currentDir, f))]
        # Check if there is at least one folder
    if folders:
        # Grab the first folder (im just expecting the one but just in case)
        firstFolder = folders[0]
        currentDir = os.path.join(currentDir, firstFolder)
        currentDir = os.path.join(currentDir, "T1_IMGS")
    return currentDir

def buildPathToNrrd(patient):
    currentDir = os.path.join(baselineLocationSeg, patient)
    #Segmentation_Breast_MRI_018_Breast.seg.nrrd
    string = "Segmentation_" + patient + "_Breast.seg.nrrd"
    currentDir = os.path.join(currentDir, string)
    return currentDir

def trawlMyRecurrences():
    df = pd.read_csv(locationOfClin)
    df['Recurrence'] = pd.to_numeric(df['Recurrence'], downcast='integer', errors='coerce')
    print(df)
    return df

trawlMyRecurrences()

def constructSeriesDirAndMaskPaths():
    series_dirs=[]
    mask_paths=[]
    df = trawlIdFile()
    recurrencedf = trawlMyRecurrences()
    filtered_rec = recurrencedf[recurrencedf['Name'].isin(df['Name'])]
    labels = filtered_rec['Recurrence'].values.tolist()
    print(labels)
    for index, row in df.iterrows():
        patient = row['Name']
        #construct path to series
        mgyPath = buildPathToSeries(patient)
        if (os.path.exists(mgyPath)):
            series_dirs.append(mgyPath)
            mask_paths.append(buildPathToNrrd(patient))
    return series_dirs, mask_paths, labels

constructSeriesDirAndMaskPaths()

from torchvision.transforms import Resize, Compose
from torch.utils.data import DataLoader

transform = Compose([
    Resize((224, 224)),  # need to see if architecture allows for this
])
series, masks, recLabels = constructSeriesDirAndMaskPaths()
dataset = BreastMRIDataset(
    series_dirs=series,
    mask_paths=masks,
    labels=recLabels,
    transform=transform,
    use_mask=True,
)

loader = DataLoader(dataset, batch_size=8, shuffle=True)

#put in pickl file  post-architecture so this isnt a pain for anyone

import torch
import torch.nn as nn
import torch.nn.functional as F

class TumorFeatureCNN(nn.Module):
    def __init__(self, use_mask=False, in_channels=1):
        super().__init__()
        self.use_mask = use_mask
        total_in = in_channels + (1 if use_mask else 0)

        self.conv1 = nn.Conv2d(total_in, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # squeeze to vector

    def forward(self, x, mask=None):
        if self.use_mask and mask is not None:
            x = torch.cat([x, mask], dim=1)  # conca-ztenate channel-wise

        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.relu(self.conv3(x))
        x = self.pool(x)
        x = x.view(x.size(0), -1)  # flatten to (B, features)
        return x  # features to send to RNN or FC layers

# Create model instance
model = TumorFeatureCNN(use_mask=False, in_channels=1)  # adjust if needed

# Move to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

df = trawlIdFile()
recurrencedf = trawlMyRecurrences()
filtered_rec = recurrencedf[recurrencedf['Name'].isin(df['Name'])]
patient_ids = filtered_rec['Name'].values.tolist()
print(patient_ids)

import pickle

# Put model in evaluation mode
model.eval()


all_features = []
all_labels = []
print("BEGIN TORCH")
with torch.no_grad():
    for inputs, masks, labels in loader:
        masks = masks.to(device)
        labels = labels.to(device)

        outputs = model(inputs, masks)  # Get feature vector
        all_features.append(outputs.cpu())
        all_labels.append(labels.cpu())

# Stack all tensors
features_tensor = torch.cat(all_features)
labels_tensor = torch.cat(all_labels)
print("pickle time")
# Save with pickle
with open("cnn_features.pkl", "wb") as f:
    pickle.dump({
      'features': features_tensor.numpy(),
      'labels':   labels_tensor.numpy(),
      'ids':      patient_ids,
    }, f)

print("Saved all CNN features and labels to cnn_features.pkl")

